# Malware-As-Images-InceptionV3
## What is this?
This study was conducted as a final project for my *Introduction to Data Science* course at the Colorado School of Mines.
The requirements for this assignment were fairly open-ended, and asked students to choose a dataset to perform an ML analysis on
in order to draw a meaningful conclusion from that dataset. 
In hopes of not only expanding my knowledge on Data Science and ML, but also concepts related to Cybersecurity, I chose to perform a study
on the idea of classifying and identifying malware as image representations rather than malware binaries. 
Today's society relies heavily on the use of computer systems. As technology continues to advance, the dependence of the ability
to exchange vast amounts of information across networks will continue to grow. To ensure that users can use computer systems and 
networks safely, and without the risk of hardware and software damage or theft of data, extensive research into the field of Cybersecurity 
must be done.

Thanks to @fieldsfieldsfields for creating the dataset, which can be found here: [Malware As Images](https://www.kaggle.com/matthewfields/malware-as-images)

## Overview
### The Images
Analysing malware through their respective image representation is a fairly new approach to malware classification and identification. The
process of converting malicious software binaries into a pixelated image consists of iterating byte-by-byte through the portable executable
of a specific malware, and converting each byte into a 3-channel RGB pixel. More information on this process and the how it was done for 
dataset used in this project can be found here: [Mallook](https://github.com/fieldsfieldsfields/mallook).
The dataset used consisted of image representations of Portable Exeutables of both malware *(malicious)* and ordinary software *(benign)*.
There were 611 image representations of malicious PEs and 488 representations of benign PEs. Each PE was represented in a few versions that
differed in interpolation scheme and DPI. 

! [image] (https://raw.githubusercontent.com/aaronaranda/Malware-As-Images-InceptionV3/main/plots/similar_mal.png)

### Related Work
A similar study was done by Microsoft and Intel in a co-operative effort to improve malware threat detection. This study was known as 
STAMINA (STAtic Malware-as-Image Network Analysis), which was an extension of Intel's prior work on malware classification using deep learning.
In short, the two corporations were able to classify malware with high accuracy using Microsoft's large, real-world dataset of static malware.
The main methodology used in STAMINA was Transfer Learning using Inception V1 architecture.

### Methodology
This study differs from STAMINA in using a pretrained instance of Inception V3 trained on ImageNet. InceptionV3 was chosen for its exceptionally high performance
and accuracy when used for image classification. To minimize the high computational cost that comes with training high performance CNNs, Transfer
Learning was used. 
In order to maximize the performance of Inception V3, the input images had to be resized to 299x299, and the 3-channel coloring was maintained.
All the of the input formatting was done with the `image_dataset_drom_directory` function from the TensorFlow Nightly API. Specifics can be seen
in the notebooks. An experimental version of TensorFlow was loaded to enable GPU optimization. The GPU used was a single Nvidia RTX 2080 Ti,
which is a CUDA enabled GPU, which allows for deep learning specific performance optimization. Once the preprocessing and setup was complete,
the model was trained for 10 epochs.

## Results 
The initial results after training Inception V3 were poor, and the average training accuracy was around 50%. The training configuration was 
restructured with the use of new layers. After 10 epochs of training on with the new stucture, the model achieved 80.7% accuracy.

! [image] (https://raw.githubusercontent.com/aaronaranda/Malware-As-Images-InceptionV3/main/plots/accuracyv3.png)

However, the results show that the model was an underfit for the data, having high bias. More fine tuning was done, and 100 of last layers in
the Inception V3 model were unfrozen for training. The model was trained for an additional 10 epochs, resulting in a maximum accuracy score of 
98.0%.

! [image] (https://raw.githubusercontent.com/aaronaranda/Malware-As-Images-InceptionV3/main/plots/inceptionv3_ac2.png)

---
### Notes
I'm an undergraduate CompSci student at the Colorado School of Mines, and as mentioned previously, this project was done for an introductory Data
Science course. I'm definitely not an expert in ML, Data Science, or Cybersecurity... (yet), but I had a great time completing this project and 
learned a lot. Any kind of feedback is more than welcomed.

### Acknowledgments
* [STAMINA Deep Learning for Malware Protection](www.intel.com/content/www/us/en/artificial-intelligence/documents/stamina-deep-learning-for-malware-protection-whitepaper.html.)
* [A Survey of Malware Detection Techniques](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.75.4594&rep=rep1&type=pdf)
* [Going Deeper with Convolutions](https://www.cs.unc.edu/~wliu/papers/GoogLeNet.pdf)
* [Classifying Malware Images with Convolutional Neural Network Models](www.enhanceit.com/blog/classifying-malware-images-with-convolutional-neural-network-models)
* [Rethinking the Inception Architecture for Computer Vision](https://arxiv.org/abs/1512.00567v3)
* [Tf.keras.applications.InceptionV3: TensorFlow Core v.2.4.1](www.tensorflow.org/api_docs/python/tf/keras/applications/InceptionV3)
* [Review: Inception-v3 â€” 1st Runner Up (Image Classification) in ILSVRC 2015](https://sh-tsang.medium.com/review-inception-v3-1st-runner-up-image-classification-in-ilsvrc-2015-17915421f77c)
